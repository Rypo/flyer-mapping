{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Plotting prospective flyer placement opportunities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import inspect\n",
    "import hashlib\n",
    "import functools\n",
    "from pathlib import Path\n",
    "import urllib.parse as uparse\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import spacy\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import inflect # https://github.com/jazzband/inflect\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import googlemaps\n",
    "import geopy\n",
    "import geopy.distance as geodist\n",
    "\n",
    "import folium\n",
    "import folium.plugins\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from bing_api import Bing\n",
    "from here_api import Here\n",
    "from _config import config\n",
    "px.set_mapbox_access_token(config.MAPBOX_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The data comes from three main sources, but is best explained in stages.\n",
    "\n",
    "#### Stage 0. Speculative list compilation\n",
    "At this stage, a simple list of locations that may have public bulletin boards was compiled. Initially, the a simple mention frequency was going to be used to filter out the most likely candidates, however, it quickly became clear that most sites were reposting the same ideas from a [single source](http://www.encounter.org/files/2914/3881/8878/Top_20_places_to_find_bulletin_boards_in_a_typical_town.pdf). As such, the list was filtered down to unique values and assigned a subjective interpretation of query difficultly. From there, non-rigorous experimentation was performed to further filter down the list by searching the keyword on [google maps](https://www.google.com/maps) and observing consistency and quality of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locations\n",
    "\n",
    "<details>\n",
    "<summary>Locations</summary>\n",
    "\n",
    "1. Grocery Stores\n",
    "2. Libraries\n",
    "3. Gyms/Recreational Facilities\n",
    "4. Churches \n",
    "5. Laundromats\n",
    "6. Coffee Shops\n",
    "7. Break Rooms/ Waiting Rooms/Lunch Rooms\n",
    "8. Factories\n",
    "9. Community Centers\n",
    "10. Union Halls\n",
    "11. Beauty Salons\n",
    "12. Bookstores\n",
    "13. Restaurants/Bars\n",
    "14. Convenience Stores\n",
    "15. Smaller Shopping Centers\n",
    "16. College and University Common Areas\n",
    "17. Shops near universities and colleges (the more they target college students, the more likely it is that they will have a board or wall of some kind)\n",
    "18. Music Stores\n",
    "19. Apartment complexes\n",
    "20. Pharmacies\n",
    "\n",
    "National Chains that often have message boards:\n",
    "* Qdoba\n",
    "* Panera Bread\n",
    "* Caribou Coffee\n",
    "* Barnes & Noble\n",
    "* Whole Foods\n",
    "* Pot Belly Sandwich Shops\n",
    "* Starbucks\n",
    "* Jimmy Johns\n",
    "* Hy-Vee\n",
    "\n",
    "\n",
    "```\n",
    "0               Grocery Store\n",
    "1                     Library\n",
    "2                         Gym\n",
    "3       Recreational Facility\n",
    "4                      Church\n",
    "5                  Laundromat\n",
    "6                 Coffee Shop\n",
    "11           Community Center\n",
    "12                 Union Hall\n",
    "13               Beauty Salon\n",
    "14                  Bookstore\n",
    "15                 Restaurant\n",
    "16                        Bar\n",
    "17          Convenience Store\n",
    "21                Music Store\n",
    "22          Apartment complex\n",
    "23                   Pharmacy\n",
    "24                      Qdoba\n",
    "25               Panera Bread\n",
    "26             Caribou Coffee\n",
    "27             Barnes & Noble\n",
    "28                 Whole Food\n",
    "29    Pot Belly Sandwich Shop\n",
    "30                   Starbuck\n",
    "31               Jimmy John's\n",
    "32                     Hy-Vee\n",
    "33                Post Office\n",
    "36                  Town Hall\n",
    "37                Barber Shop\n",
    "38              Beauty Parlor\n",
    "39                 Nail Salon\n",
    "40            Ice Cream Stand\n",
    "41                Supermarket\n",
    "42                    College\n",
    "43                       Mall\n",
    "45                     Doctor\n",
    "47                    Dentist\n",
    "49                Gas Station\n",
    "51           Auto Repair Shop\n",
    "52            Day Care Center\n",
    "53        Chamber of Commerce\n",
    "54                       Bank\n",
    "55               Credit Union\n",
    "56             Hardware Store\n",
    "57             Fitness Center\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Sources: \n",
    "\n",
    "http://www.encounter.org/files/2914/3881/8878/Top_20_places_to_find_bulletin_boards_in_a_typical_town.pdf\n",
    "\n",
    "https://www.psprint.com/resources/ultimate-list-of-places-to-distribute-your-flyers/\n",
    "\n",
    "https://mikecooney.net/22-great-places-hang-flyers/\n",
    "\n",
    "https://grab-its.com/tips.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key=config.GMAPS_KEY, timeout=10, retry_over_query_limit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAD=40000 # 40000m â‰ˆ 25 miles\n",
    "METERMILE = 1609.344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjective groupings, can be improved by instead grouping on co-occurance frequency\n",
    "place_groups = {\n",
    "    'food':       ['grocery_or_supermarket','bakery','food','supermarket'],\n",
    "    'dining_out': ['cafe','restaurant','meal_takeaway','meal_delivery'],#new\n",
    "    'alcohol':    ['bar', 'night_club', 'liquor_store'], #new\n",
    "    'park_camp':  ['park','campground','amusement_park'],#new\n",
    "    'academic':   ['library','university','school', 'book_store'],\n",
    "    'health':     ['gym', 'pharmacy', 'doctor', 'dentist', 'health'],\n",
    "    'beauty':     ['beauty_salon','hair_care','spa'], #new\n",
    "    'finance':    ['finance', 'bank', 'atm','accounting'],\n",
    "    'automotive': ['gas_station', 'car_repair','car_wash, gas_station','convenience_store','car_dealer'],\n",
    "    'government': ['local_government_office','post_office','city_hall','courthouse'],\n",
    "    'services':   ['general_contractor','laundry','real_estate_agency','florist'],\n",
    "    'stores':     ['electronics_store','hardware_store','department_store','shopping_mall','store'],\n",
    "    'religious':  ['church','place_of_worship'],#new\n",
    "    'other':      ['point_of_interest','establishment','tourist_attraction']\n",
    "}\n",
    "pg_rev = {x:k for k,v in place_groups.items() for x in v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcolico = [\n",
    "    ('food','red','shopping-basket'),\n",
    "    ('dining_out','orange','cutlery'),\n",
    "    ('alcohol','purple','glass'),\n",
    "    ('park_camp','darkgreen','tree'),\n",
    "    ('academic','blue','graduation-cap'),\n",
    "    ('health','lightred','heartbeat'),\n",
    "    ('beauty','lightblue','scissors'),\n",
    "    ('finance','green','dollar'),\n",
    "    ('automotive','pink','car'),\n",
    "    ('government','beige','gavel'),\n",
    "    ('services','darkpurple','cubes'),\n",
    "    ('stores','darkred','shopping-cart'),\n",
    "    ('religious','lightgray','cloud'),\n",
    "    ('community','cadetblue','universal-access'), # special; not in place groups\n",
    "    ('other','gray','question')]\n",
    "\n",
    "color_map = {cat:col for cat,col,_ in catcolico}\n",
    "faicon_map = {cat:ico for cat,_,ico in catcolico}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed icons: [,,,,,,,'bell',,'info-circle']\n",
    "# Unused colors:  ['darkblue', ,'white','lightgreen','black'] 'cadetblue'\n",
    "# group_glyicons=['cutlery','glass','education','heart-empty','usd','road','flag','bell','shopping-cart','info-sign']\n",
    "# glyicon_map = {k:v for k,v in zip(place_groups.keys(),group_glyicons)}\n",
    "# group_faicons=['cutlery','glass','graduation-cap','heartbeat','dollar','car','gavel','bell','shopping-cart','info-circle']# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred','lightred', \n",
    "                'beige', 'darkblue', 'darkgreen', 'cadetblue','darkpurple','white',\n",
    "                'pink', 'lightblue', 'lightgreen','gray', 'black', 'lightgray']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "all_types=['accounting', 'airport', 'amusement_park', 'aquarium',\n",
    "       'art_gallery', 'atm', 'bakery', 'bank', 'bar', 'beauty_salon',\n",
    "       'bicycle_store', 'book_store', 'bowling_alley', 'bus_station',\n",
    "       'cafe', 'campground', 'car_dealer', 'car_rental', 'car_repair',\n",
    "       'car_wash', 'casino', 'cemetery', 'church', 'city_hall',\n",
    "       'clothing_store', 'convenience_store', 'courthouse', 'dentist',\n",
    "       'department_store', 'doctor', 'drugstore', 'electrician',\n",
    "       'electronics_store', 'embassy', 'fire_station', 'florist',\n",
    "       'funeral_home', 'furniture_store', 'gas_station',\n",
    "       'grocery_or_supermarket', 'gym', 'hair_care', 'hardware_store',\n",
    "       'hindu_temple', 'home_goods_store', 'hospital', 'insurance_agency',\n",
    "       'jewelry_store', 'laundry', 'lawyer', 'library',\n",
    "       'light_rail_station', 'liquor_store', 'local_government_office',\n",
    "       'locksmith', 'lodging', 'meal_delivery', 'meal_takeaway', 'mosque',\n",
    "       'movie_rental', 'movie_theater', 'moving_company', 'museum',\n",
    "       'night_club', 'painter', 'park', 'parking', 'pet_store',\n",
    "       'pharmacy', 'physiotherapist', 'plumber', 'police', 'post_office',\n",
    "       'primary_school', 'real_estate_agency', 'restaurant',\n",
    "       'roofing_contractor', 'rv_park', 'school', 'secondary_school',\n",
    "       'shoe_store', 'shopping_mall', 'spa', 'stadium', 'storage',\n",
    "       'store', 'subway_station', 'supermarket', 'synagogue',\n",
    "       'taxi_stand', 'tourist_attraction', 'train_station',\n",
    "       'transit_station', 'travel_agency', 'university',\n",
    "       'veterinary_care', 'zoo']\n",
    "\n",
    "keeptypes = ['book_store','bus_station','city_hall','convenience_store','gas_station',\n",
    "             'laundry','library', 'local_government_office', 'secondary_school','university']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available icons:\n",
    "\n",
    "https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css\n",
    "\n",
    "https://fontawesome.com/v4.7.0/icons/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IO Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_path(keyword, fpath=None):\n",
    "    # make keyword filename safe\n",
    "    kw = re.sub(r\"[\\.\\-';:&]\",'',keyword).lower().replace(' ','_') \n",
    "    file = (Path(fpath)/kw).with_suffix('.json')\n",
    "    return file\n",
    "\n",
    "def validate_open(fname, fpath=None, no_overwrite=True):\n",
    "    file = keyword_path(fname, fpath)\n",
    "    if file.exists() and no_overwrite:\n",
    "        raise FileExistsError(f'{file.as_posix()} exists, overwrite not permitted')\n",
    "    return open(file, 'w', encoding='utf-8')\n",
    "\n",
    "def read_json(fname, fpath=None):\n",
    "    file = keyword_path(fname, fpath)\n",
    "    # No safe handling for missing files\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def concat_jsons(dirpath, outname):\n",
    "    dirpath = Path(dirpath)\n",
    "    files = [*dirpath.iterdir()]\n",
    "    jlist = []\n",
    "    for f in files:\n",
    "        with f.open('r') as fp:\n",
    "            jsf = json.load(fp)\n",
    "            jsf['file_stem'] = f.stem\n",
    "            jlist.append(jsf)\n",
    "    json.dump(jlist,(dirpath/outname).open('w'))\n",
    "    return json.load((dirpath/outname).open('r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_jsave(saveobj, fpath):\n",
    "    try:\n",
    "        if saveobj and fpath is not None:\n",
    "            with open(fpath,'w', encoding='utf-8') as fp: \n",
    "                json.dump(saveobj, fp, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        print('ERROR:', e, e.args)\n",
    "    finally:\n",
    "        return saveobj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HASHLOG=Path(config.paths.HASHLOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def hsfn(fn,*args,**kwargs):\n",
    "    \"\"\"Create a hash value for any function, parameters combination\"\"\"\n",
    "    hlog = HASHLOG.read_text()\n",
    "    dryrun = kwargs.pop('dryrun',False)\n",
    "    bound = inspect.signature(fn).bind(*args,**kwargs)\n",
    "    storeargs = {'module':fn.__module__,'name':fn.__name__,**bound.arguments}\n",
    "    jstr = json.dumps(storeargs,default=str)\n",
    "    \n",
    "    s256 = hashlib.sha256(jstr.encode())\n",
    "    hsh = s256.hexdigest()+'\\n'\n",
    "\n",
    "    if hsh not in hlog:\n",
    "        HASHLOG.open(mode='a').write(hsh)\n",
    "        if not dryrun:\n",
    "            return fn(*args, **kwargs)\n",
    "    else:\n",
    "        print(f'Skipping... hashed fncall found ({hsh[:7]}...)')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several things can go wrong with the hashing function:\n",
    "1. It depends on EXACT parameter matches or it will be an entirely different hash value.\n",
    "    * If the 6th decimal on a longitude/latitude value is off, new hash\n",
    "    * The same is true for any changes to radius, despite undoubtedly many overlapping results.\n",
    "    * Inconsistent capitalization of keywords would also cause duplication.\n",
    "    * The order in which keywords are passed also matters. This can be fixed with a sort, however.\n",
    "    * If 98 out of 99 destination distances overlap, but 1 differs...new entry\n",
    "2. There is no 'closeness' metric, a call to `gmaps.places_nearby` with a small parameter change is no more different than a call to `gmaps.distance_matrix` or even `np.random.randint`. This could be partially alleviated by different storage files for different functions.\n",
    "3. It can't account for functionally equivalent statements such as `geopy.GoogleV3.reverse` and `gmaps.reverse_geocode`\n",
    "4. If the log file is corrupted or lost, all calls will need to be 'dry run' again with identical params to populate it.\n",
    "\n",
    "Problem 1 could potentially be made slightly better by levenshtein distance of param strings prior to encoding.\n",
    "\n",
    "A far more robust, maintainable, and likely performant solution would be to simply use a MongoDB server and pymongo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def hashstore(func):\n",
    "    \"\"\"Works for top-level functions, otherwise not useful\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_hashstore(*args, **kwargs):\n",
    "        hlog = HASHLOG.read_text()\n",
    "        hsh = hsfn(func,*args,**kwargs)\n",
    "        if hsh not in hlog:\n",
    "            HASHLOG.open(mode='a').write(hsh)\n",
    "            return func(*args, **kwargs)\n",
    "        else:\n",
    "            print(f'hashed fncall found ({hsh[:7]}...), skipping...')\n",
    "    return wrapper_hashstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def partition_groups(iterable, n_groups=None, max_group_size=None):\n",
    "    assert (n_groups or max_group_size) is not None, 'exactly one of `n_groups` or `max_group_size` must be provided'\n",
    "    n_groups = n_groups if n_groups is not None else np.ceil(len(iterable)/(max_group_size))\n",
    "    return np.array_split(iterable, n_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maps Api Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for a single place by using the ID allows you to choose which [fields](https://developers.google.com/places/web-service/details#fields) are returned and costs less. This uses `gmaps.place()` if searching by id, or `gmaps.find_place()` if finding by text query.\n",
    "\n",
    "https://developers.google.com/places/web-service/search#FindPlaceRequests\n",
    "\n",
    "https://cloud.google.com/maps-platform/pricing/sheet/\n",
    "\n",
    "https://developers.google.com/maps/billing/gmp-billing#data-skus\n",
    "\n",
    "https://developers.google.com/maps/documentation/distance-matrix/intro#DistanceMatrixResponses\n",
    "\n",
    "Based on the [gmaps billing calculator](https://mapsplatformtransition.withgoogle.com/calculator), place details is the most expensive API call for basic tier responses, costing ~$17/1000 requests. It provides little benefit over a broad area search, and should be avoided when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ggeocode(ggeo_func, location, fpath=None, **kwargs):\n",
    "    \"\"\"Geo-encoding if reverse=True, location is (lat,long) otherwise a human readable address\"\"\"\n",
    "    resp = hsfn(ggeo_func, location, exactly_one=True, **kwargs)\n",
    "\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gplaceid(query, coords, fpath=None, radius=20, store_hash=False, **kwargs):\n",
    "    \"\"\"Find nearest place_id that matches a given query\"\"\"\n",
    "    lb = 'circle:{}@{},{}'.format(radius,*coords)\n",
    "    if store_hash:\n",
    "        resp = hsfn(gmaps.find_place, query, input_type='textquery', location_bias=lb, language='en', **kwargs)\n",
    "    else:\n",
    "        resp = gmaps.find_place(query, input_type='textquery', location_bias=lb, language='en')\n",
    "    return try_jsave(resp,fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# TODO: make a list of place_ids that have already been detailed\n",
    "# skip the place lookup if information already is available\n",
    "# fill in from the database with a notification that it was pulled locally\n",
    "# gplace_details_df\n",
    "def gpdetails_df(df, query_col, coord_col, fpath=None, radius=20, keep_fields=None, id_only=True,**kwargs):\n",
    "    \"\"\"Returns details or place ids of the nearest place fitting given critera \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas.DataFrame, \n",
    "        DataFrame containing infomation to pass to gmaps find place API\n",
    "    query_col : str, \n",
    "        Column in `df` containing query strings\n",
    "    coord_col : str, \n",
    "        Column in `df` containing [latitude,longitude] coordinates\n",
    "    fpath : str, (default: None)\n",
    "        Path to save the json API responses\n",
    "    radius : int, (default: 20)\n",
    "        Search radius(meters) used to find the nearest matching result\n",
    "    keep_fields : list[str], (default: ['formatted_address','geometry', 'icon', 'name',\n",
    "        'permanently_closed', 'place_id', 'plus_code', 'type', 'url', 'vicinity'])\n",
    "        Fields to keep from the place details response\n",
    "    id_only : boolean, (default: True)\n",
    "        If true, only place_ids will be returned, which is a non-billed operation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of json resposnes or place_ids\n",
    "    \"\"\"\n",
    "    dfm = df[[query_col,coord_col]]\n",
    "    places = [gplaceid(q, co, fpath=fpath, radius=radius) for q,co in dfm.values]\n",
    "    if id_only:\n",
    "        return places\n",
    "    else: # explict else to emphasize if and only if \n",
    "        if fpath is None:\n",
    "             raise IOError('Expensive query. `fpath` before proceeding')\n",
    "        if keep_fields is None:\n",
    "            #'adr_address','address_component','photo','utc_offset'\n",
    "            keep_fields = ['formatted_address', 'geometry', 'icon', 'name', 'permanently_closed', \n",
    "                           'place_id', 'plus_code', 'type', 'url', 'vicinity']\n",
    "\n",
    "        results = []\n",
    "        for pid in places:\n",
    "            first_pid = pid['candidates'][0]['place_id']\n",
    "            resp = hsfn(gmaps.place, place_id=first_pid, fields=keep_fields, language='en')\n",
    "            if resp is not None:\n",
    "                results.append(resp)\n",
    "\n",
    "        return try_jsave(results,fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# gdist_save\n",
    "def gdistances(destinations, origin, fpath, max_ele=100, **kwargs):\n",
    "    \"\"\"Calculate distance between up to 99 destinations from a single origin point\"\"\"\n",
    "    dest_parts = partition_groups(destinations, max_group_size=(max_ele-1)) # subtract 1 for Origin\n",
    "    origin = tuple(origin)\n",
    "    results = []\n",
    "    for part in dest_parts:\n",
    "        resp = hsfn(gmaps.distance_matrix, origins=origin, destinations=part, units='imperial', language='en', **kwargs)\n",
    "        if resp is not None:\n",
    "            results.append(resp)\n",
    "\n",
    "    return try_jsave(results,fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdistances_df(df, dests_col, origins_col, fpath, max_ele=100, **kwargs):\n",
    "    ori_dests = df.groupby(df[origins_col].astype(str))[dests_col].apply(list)\n",
    "    results = [gdistances(ds, destring_list(o,' '),max_ele=max_ele) for o,ds in ori_dests.items()]\n",
    "    return try_jsave(results,fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gquery_save\n",
    "def gsearchNB(query, coords, fpath=None, radius=40000, **kwargs):\n",
    "    \"\"\"Search for places near a location based on a text query. \n",
    "    Finds a maximum of 20 results per query,coords pair\"\"\"\n",
    "    coords = tuple(coords)\n",
    "    resp = hsfn(gmaps.places_nearby, location=coords, radius=radius, keyword=query, language='en', **kwargs)\n",
    "    if resp is not None:\n",
    "        resp.update({'query':query,'origin':coords,'radius':radius})\n",
    "    return try_jsave(resp,fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# gquery_df_save\n",
    "def gsearchNB_df(df, query_col, coord_col, fpath, radius=40000, **kwargs):\n",
    "    \"\"\"Search for places near locations based on a text queries using values from a DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas.DataFrame, \n",
    "        DataFrame containing infomation to pass to gmaps find place API\n",
    "    query_col : str, \n",
    "        Column in `df` containing query strings\n",
    "    coord_col : str, \n",
    "        Column in `df` containing [latitude,longitude] coordinates\n",
    "    fpath : str, (default: None)\n",
    "        Path to save the json API responses\n",
    "    radius : int, (default: 20)\n",
    "        Search radius(meters) used to find the nearest matching result\n",
    "    \"\"\"\n",
    "    dfm = df[[query_col,coord_col]]\n",
    "    results = []\n",
    "    for query,coords in dfm.values:\n",
    "        coords = tuple(coords) # cast as tuple in case it is np array\n",
    "        resp = hsfn(gmaps.places_nearby, location=coords, radius=radius, keyword=query, language='en', **kwargs)\n",
    "        if resp is not None:\n",
    "            resp.update({'query':query,'origin':coords,'radius':radius})\n",
    "            results.append(resp)\n",
    "            \n",
    "    return try_jsave(results,fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_query_fields(query, fpath=None):\n",
    "    response = read_json(query, fpath=fpath)\n",
    "    places = response['results']\n",
    "    for place in places:\n",
    "        yield {\n",
    "            'place_name': place['name'],\n",
    "            'latlong': tuple(place['geometry']['location'].values()),\n",
    "            'vicinity': place['vicinity'],\n",
    "            'keyword': query,\n",
    "            'types': place['types'],\n",
    "            'rating': place['rating'],\n",
    "            'n_ratings': place['user_ratings_total'],\n",
    "            'place_id': place['place_id']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_dist_fields(fname, fpath=None):\n",
    "    gdist_dict = read_json(fname,fpath)\n",
    "    for dest_addr, dist_data in zip(gdist_dict['destination_addresses'], gdist_dict['rows'][0]['elements']):\n",
    "        yield {\n",
    "            'dest_addr':dest_addr,\n",
    "            'meters': dist_data['distance']['value'],\n",
    "            'seconds': dist_data['duration']['value']\n",
    "            #'miles': dist_data['distance']['text'],\n",
    "            #'minutes': dist_data['duration']['text'],\n",
    "        }        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_detail_fields(pdetails_list):\n",
    "    for pdt in pdetails_list:\n",
    "        yield {\n",
    "            'place_name': pdt['name'],\n",
    "            'address':pdt['formatted_address'].strip(', USA'),\n",
    "            'latlng': np.round([*pdt['geometry']['location'].values()],6),\n",
    "            'types': pdt['types'],\n",
    "            'icon': pdt['icon'].split('/')[-1], # PREFIX: https://maps.gstatic.com/mapfiles/place_api/icons/\n",
    "            'global_pcode': pdt['plus_code']['global_code'],\n",
    "            'place_id': pdt['place_id'],\n",
    "            'cid': pdt['url'].split('=')[-1], # PREFIX: https://maps.google.com/?cid=\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare manually collected list of potential flyer locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gkgsearch(query,limit=10,indent=True,apikey=None):\n",
    "    b_url = 'https://kgsearch.googleapis.com'\n",
    "    pth = '/v1/'\n",
    "    rsc = 'entities:search'\n",
    "    url_path = b_url+pth+rsc\n",
    "    params = {\n",
    "        'query': query,\n",
    "        'limit': limit,\n",
    "        'indent': indent,\n",
    "        'key': apikey,\n",
    "    }\n",
    "    resp = requests.get(url_path, params=params)\n",
    "    jresp = resp.json()\n",
    "    return jresp.get('itemListElement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Places</th>\n",
       "      <th>HardQuery</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Grocery Stores</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Libraries</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Gyms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Recreational Facilities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Churches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Places HardQuery Comments\n",
       "0           Grocery Stores       NaN      NaN\n",
       "1                Libraries       NaN      NaN\n",
       "2                     Gyms       NaN      NaN\n",
       "3  Recreational Facilities       NaN      NaN\n",
       "4                 Churches       NaN      NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs_df = pd.read_csv('data/csv/flyerlocs.csv').drop_duplicates('Places')\n",
    "locs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kg(queries, lim=1, key=None):\n",
    "    df_kg = pd.concat([json_normalize(gkgsearch(q, limit=lim, apikey=key),sep='_').assign(keyword=q) \n",
    "        for q in queries], sort=False).reset_index(drop=True)\n",
    "\n",
    "    # Clean names and drop unused columns\n",
    "    df_kg = (df_kg.drop(columns=[\n",
    "        '@type','result_image_contentUrl','result_image_url','result_detailedDescription_license'\n",
    "    ]).rename(lambda x: re.sub(r'result_?|@|etailedD|article','',x).lower(), axis=1))\n",
    "    # Re-order columns\n",
    "    return df_kg[['score','keyword','name','description','type','description_body','url','description_url','id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>keyword</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>type</th>\n",
       "      <th>description_body</th>\n",
       "      <th>url</th>\n",
       "      <th>description_url</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29.009920</td>\n",
       "      <td>Grocery Stores</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Retail company</td>\n",
       "      <td>[Organization, Thing, Corporation]</td>\n",
       "      <td>Walmart Inc. is an American multinational reta...</td>\n",
       "      <td>http://www.walmart.com/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Walmart</td>\n",
       "      <td>kg:/m/0841v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>39.676849</td>\n",
       "      <td>Libraries</td>\n",
       "      <td>Greenwood Publishing Group</td>\n",
       "      <td>Publishing company</td>\n",
       "      <td>[Organization, Thing, Corporation]</td>\n",
       "      <td>ABC-CLIO/Greenwood is an educational and acade...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Greenwood_Publis...</td>\n",
       "      <td>kg:/m/03npz5m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1151.340088</td>\n",
       "      <td>Gyms</td>\n",
       "      <td>ClassPass</td>\n",
       "      <td>Company</td>\n",
       "      <td>[Thing, Corporation, Organization]</td>\n",
       "      <td>ClassPass Inc. an American company which provi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/ClassPass</td>\n",
       "      <td>kg:/m/0130gnq4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.534503</td>\n",
       "      <td>Recreational Facilities</td>\n",
       "      <td>Bombardier Recreational Products</td>\n",
       "      <td>Manufacturing company</td>\n",
       "      <td>[Corporation, Thing, Organization]</td>\n",
       "      <td>BRP Inc. is a Canadian company making various ...</td>\n",
       "      <td>http://www.brp.com</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bombardier_Recre...</td>\n",
       "      <td>kg:/m/0343nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6067.500000</td>\n",
       "      <td>Coffee Shops</td>\n",
       "      <td>Tully's Coffee</td>\n",
       "      <td>Retail chain</td>\n",
       "      <td>[Corporation, Organization, Thing, Restaurant]</td>\n",
       "      <td>Tully's Coffee is an American specialty coffee...</td>\n",
       "      <td>http://tullyscoffeeshops.com/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tully's_Coffee</td>\n",
       "      <td>kg:/m/032716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score                  keyword                              name  \\\n",
       "0    29.009920           Grocery Stores                           Walmart   \n",
       "1    39.676849                Libraries        Greenwood Publishing Group   \n",
       "2  1151.340088                     Gyms                         ClassPass   \n",
       "3     1.534503  Recreational Facilities  Bombardier Recreational Products   \n",
       "4  6067.500000             Coffee Shops                    Tully's Coffee   \n",
       "\n",
       "             description                                            type  \\\n",
       "0         Retail company              [Organization, Thing, Corporation]   \n",
       "1     Publishing company              [Organization, Thing, Corporation]   \n",
       "2                Company              [Thing, Corporation, Organization]   \n",
       "3  Manufacturing company              [Corporation, Thing, Organization]   \n",
       "4           Retail chain  [Corporation, Organization, Thing, Restaurant]   \n",
       "\n",
       "                                    description_body  \\\n",
       "0  Walmart Inc. is an American multinational reta...   \n",
       "1  ABC-CLIO/Greenwood is an educational and acade...   \n",
       "2  ClassPass Inc. an American company which provi...   \n",
       "3  BRP Inc. is a Canadian company making various ...   \n",
       "4  Tully's Coffee is an American specialty coffee...   \n",
       "\n",
       "                             url  \\\n",
       "0        http://www.walmart.com/   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3             http://www.brp.com   \n",
       "4  http://tullyscoffeeshops.com/   \n",
       "\n",
       "                                     description_url              id  \n",
       "0              https://en.wikipedia.org/wiki/Walmart     kg:/m/0841v  \n",
       "1  https://en.wikipedia.org/wiki/Greenwood_Publis...   kg:/m/03npz5m  \n",
       "2            https://en.wikipedia.org/wiki/ClassPass  kg:/m/0130gnq4  \n",
       "3  https://en.wikipedia.org/wiki/Bombardier_Recre...    kg:/m/0343nb  \n",
       "4       https://en.wikipedia.org/wiki/Tully's_Coffee    kg:/m/032716  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_df = build_kg(locs_df.Places, key=config.GKG_KEY); kg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_named_ents(df, min_score=5000, min_kw_ratio=85, desc_kw='company', types_filter=None):\n",
    "    \"\"\"Apply multiple masks to attempt to isolate named entities\"\"\"\n",
    "    types_filter = set(types_filter) if types_filter is not None else set(['Organization', 'Corporation'])\n",
    "    mask_score = df['score'] > min_score\n",
    "    mask_kw = [fuzz.UWRatio(x,y) > min_kw_ratio for x,y in df[['keyword','name']].values]\n",
    "    mask_desc = df['description'].str.contains(desc_kw,case=False)\n",
    "    mask_types = df['type'].apply(lambda x: types_filter.issubset(x))\n",
    "    \n",
    "    return df[(mask_score & mask_kw & mask_desc & mask_types)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>keyword</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>type</th>\n",
       "      <th>description_body</th>\n",
       "      <th>url</th>\n",
       "      <th>description_url</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>6114.409180</td>\n",
       "      <td>Qdoba</td>\n",
       "      <td>Qdoba</td>\n",
       "      <td>Restaurant company</td>\n",
       "      <td>[Thing, Organization, Corporation, Restaurant]</td>\n",
       "      <td>Qdoba Mexican Eats\\nis a chain of fast casual ...</td>\n",
       "      <td>http://www.qdoba.com</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Qdoba</td>\n",
       "      <td>kg:/m/05rqh3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>55637.910156</td>\n",
       "      <td>Panera Bread</td>\n",
       "      <td>Panera Bread</td>\n",
       "      <td>Bakery company</td>\n",
       "      <td>[Restaurant, Thing, Corporation, Organization]</td>\n",
       "      <td>Panera Bread Company is an American chain stor...</td>\n",
       "      <td>http://www.panerabread.com</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Panera_Bread</td>\n",
       "      <td>kg:/m/03pk18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>10366.417969</td>\n",
       "      <td>Caribou Coffee</td>\n",
       "      <td>Caribou Coffee</td>\n",
       "      <td>Company</td>\n",
       "      <td>[Organization, Thing, Corporation, Restaurant]</td>\n",
       "      <td>Caribou Coffee Company is an American coffee c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Caribou_Coffee</td>\n",
       "      <td>kg:/m/03p1q_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>94895.757812</td>\n",
       "      <td>Barnes &amp; Noble</td>\n",
       "      <td>Barnes &amp;amp; Noble</td>\n",
       "      <td>Retail outlet company</td>\n",
       "      <td>[Corporation, Organization, Thing]</td>\n",
       "      <td>Barnes &amp;amp; Noble, Inc., is an American books...</td>\n",
       "      <td>http://www.barnesandnobleinc.com/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Barnes_%26_Noble</td>\n",
       "      <td>kg:/m/01b7dt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>28937.314453</td>\n",
       "      <td>Whole Foods</td>\n",
       "      <td>Whole Foods Market</td>\n",
       "      <td>Supermarket company</td>\n",
       "      <td>[Organization, LocalBusiness, Corporation, Thing]</td>\n",
       "      <td>Whole Foods Market Inc. is an American multina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Whole_Foods_Market</td>\n",
       "      <td>kg:/m/02xf2l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>29544.181641</td>\n",
       "      <td>Potbelly Sandwich Shop</td>\n",
       "      <td>Potbelly Sandwich Shop</td>\n",
       "      <td>Restaurant company</td>\n",
       "      <td>[Restaurant, Thing, Corporation, Organization]</td>\n",
       "      <td>Potbelly Corporation is a publicly traded rest...</td>\n",
       "      <td>http://www.potbelly.com/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Potbelly_Sandwic...</td>\n",
       "      <td>kg:/m/05g_n0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>25809.320312</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>Coffee company</td>\n",
       "      <td>[Organization, Thing, Corporation, Restaurant]</td>\n",
       "      <td>Starbucks Corporation is an American coffee co...</td>\n",
       "      <td>http://www.starbucks.com</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Starbucks</td>\n",
       "      <td>kg:/m/018c_r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>52278.152344</td>\n",
       "      <td>Jimmy John's</td>\n",
       "      <td>Jimmy John's</td>\n",
       "      <td>Fast food restaurant company</td>\n",
       "      <td>[Thing, Organization, Restaurant, Corporation]</td>\n",
       "      <td>Jimmy John's Franchise, LLC is an American fra...</td>\n",
       "      <td>http://www.jimmyjohns.com</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jimmy_John's</td>\n",
       "      <td>kg:/m/05pqt1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>18910.541016</td>\n",
       "      <td>Hy-Vee</td>\n",
       "      <td>Hy-Vee</td>\n",
       "      <td>Supermarket company</td>\n",
       "      <td>[Organization, Thing, Corporation]</td>\n",
       "      <td>Hy-Vee is a chain of more than 245 supermarket...</td>\n",
       "      <td>http://www.hy-vee.com</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hy-Vee</td>\n",
       "      <td>kg:/m/02vg5b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score                 keyword                    name  \\\n",
       "18   6114.409180                   Qdoba                   Qdoba   \n",
       "19  55637.910156            Panera Bread            Panera Bread   \n",
       "20  10366.417969          Caribou Coffee          Caribou Coffee   \n",
       "21  94895.757812          Barnes & Noble      Barnes &amp; Noble   \n",
       "22  28937.314453             Whole Foods      Whole Foods Market   \n",
       "23  29544.181641  Potbelly Sandwich Shop  Potbelly Sandwich Shop   \n",
       "24  25809.320312               Starbucks               Starbucks   \n",
       "25  52278.152344            Jimmy John's            Jimmy John's   \n",
       "26  18910.541016                  Hy-Vee                  Hy-Vee   \n",
       "\n",
       "                     description  \\\n",
       "18            Restaurant company   \n",
       "19                Bakery company   \n",
       "20                       Company   \n",
       "21         Retail outlet company   \n",
       "22           Supermarket company   \n",
       "23            Restaurant company   \n",
       "24                Coffee company   \n",
       "25  Fast food restaurant company   \n",
       "26           Supermarket company   \n",
       "\n",
       "                                                 type  \\\n",
       "18     [Thing, Organization, Corporation, Restaurant]   \n",
       "19     [Restaurant, Thing, Corporation, Organization]   \n",
       "20     [Organization, Thing, Corporation, Restaurant]   \n",
       "21                 [Corporation, Organization, Thing]   \n",
       "22  [Organization, LocalBusiness, Corporation, Thing]   \n",
       "23     [Restaurant, Thing, Corporation, Organization]   \n",
       "24     [Organization, Thing, Corporation, Restaurant]   \n",
       "25     [Thing, Organization, Restaurant, Corporation]   \n",
       "26                 [Organization, Thing, Corporation]   \n",
       "\n",
       "                                     description_body  \\\n",
       "18  Qdoba Mexican Eats\\nis a chain of fast casual ...   \n",
       "19  Panera Bread Company is an American chain stor...   \n",
       "20  Caribou Coffee Company is an American coffee c...   \n",
       "21  Barnes &amp; Noble, Inc., is an American books...   \n",
       "22  Whole Foods Market Inc. is an American multina...   \n",
       "23  Potbelly Corporation is a publicly traded rest...   \n",
       "24  Starbucks Corporation is an American coffee co...   \n",
       "25  Jimmy John's Franchise, LLC is an American fra...   \n",
       "26  Hy-Vee is a chain of more than 245 supermarket...   \n",
       "\n",
       "                                  url  \\\n",
       "18               http://www.qdoba.com   \n",
       "19         http://www.panerabread.com   \n",
       "20                                NaN   \n",
       "21  http://www.barnesandnobleinc.com/   \n",
       "22                                NaN   \n",
       "23           http://www.potbelly.com/   \n",
       "24           http://www.starbucks.com   \n",
       "25          http://www.jimmyjohns.com   \n",
       "26              http://www.hy-vee.com   \n",
       "\n",
       "                                      description_url             id  \n",
       "18                https://en.wikipedia.org/wiki/Qdoba   kg:/m/05rqh3  \n",
       "19         https://en.wikipedia.org/wiki/Panera_Bread   kg:/m/03pk18  \n",
       "20       https://en.wikipedia.org/wiki/Caribou_Coffee  kg:/m/03p1q_2  \n",
       "21     https://en.wikipedia.org/wiki/Barnes_%26_Noble   kg:/m/01b7dt  \n",
       "22   https://en.wikipedia.org/wiki/Whole_Foods_Market   kg:/m/02xf2l  \n",
       "23  https://en.wikipedia.org/wiki/Potbelly_Sandwic...   kg:/m/05g_n0  \n",
       "24            https://en.wikipedia.org/wiki/Starbucks   kg:/m/018c_r  \n",
       "25         https://en.wikipedia.org/wiki/Jimmy_John's   kg:/m/05pqt1  \n",
       "26               https://en.wikipedia.org/wiki/Hy-Vee   kg:/m/02vg5b  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_named_ents(kg_df,min_kw_ratio=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_placelist(df_locs, outfile=None, ents=None):\n",
    "    df = df_locs.copy()\n",
    "    df['hard_query'] = df['HardQuery'].notna()\n",
    "    df['named_ent'] = df['Places'].isin(ents)\n",
    "    # Convert to non-entities to singular form; plural form alters query results\n",
    "    ie = inflect.engine()\n",
    "    df['singular'] = df.apply(lambda x: ie.singular_noun(x['Places']) if not x['named_ent'] else x['Places'],axis=1) \n",
    "    df = df[['Places','singular','named_ent','hard_query']]\n",
    "    df['singular'] = df['singular'].where(df['singular'] != False, df['Places'])\n",
    "    df.loc[:,['Places','singular']] = df[['Places','singular']].applymap(str.strip)\n",
    "\n",
    "    if outfile is not None:\n",
    "        df.to_csv(outfile,index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locs_df = proc_placelist(locs_df,'data/csv/location_list.csv',find_named_ents(kg_df).keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_df = pd.read_csv('data/csv/location_list.csv')\n",
    "qlist = locs_df['singular'].where(~(locs_df['hard_query'])).dropna().drop_duplicates() # Omit awkwardly phrased queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Query\n",
    "The first call to any API. This begins gathering results for all of the items in the list of potential establishments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_groups(df, groupmap, types_col='types',name_col='place_name'):\n",
    "    first_types = df[types_col].str[0]\n",
    "    uncat_types = first_types.isin(['point_of_interest','establishment'])\n",
    "    # Recreation/Community Centers\n",
    "    mask_recr = uncat_types & df[name_col].str.contains(r'rec|community',case=False)\n",
    "    # Chambers of Commerce\n",
    "    mask_cmbr = uncat_types & df[name_col].str.contains(r'chamber',case=False)\n",
    "    place_groups = first_types.map(groupmap).mask(mask_recr, 'community').mask(mask_cmbr,'government')\n",
    "    return place_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destring_list(liststr,resep=r',\\s*'):\n",
    "    # 6 digits of precision is accurate to ~11cm, anything further is likely noise\n",
    "    # https://gis.stackexchange.com/questions/8650/measuring-accuracy-of-latitude-and-longitude\n",
    "    return np.round([*map(np.float,re.split(resep,liststr.strip('[( )]')))],6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_group_rename(proc_df, groupmap=None):\n",
    "    df = proc_df.copy()\n",
    "    start_drop = ['icon','id','photos','reference','scope','compound_code','url']\n",
    "    rename_map = {'query':'keyword', 'ratings_total':'n_ratings', 'name':'place_name', 'formatted_address':'dest_addr'}\n",
    "    \n",
    "    df.columns = df.columns.str.split('_').str[-2:].str.join('_').str.replace('location_','').str.strip()\n",
    "    df = df.drop(columns=start_drop,errors='ignore').rename(columns=rename_map)\n",
    "    \n",
    "    if groupmap is not None:\n",
    "        df['place_group'] = update_groups(df, groupmap, types_col='types', name_col='place_name')\n",
    "    df['latlong'] = df.apply(lambda x: np.round([x['lat'],x['lng']],6), axis=1)\n",
    "    \n",
    "    end_drop = ['lat','lng',*df.filter(like='st_l')]\n",
    "    df = df.drop(columns=end_drop, errors='ignore')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe_placeid(df, masterdf_path='data/pdflyers_df.pkl'):\n",
    "    \"\"\"Filter duplicate place_ids to reduce API cost\"\"\"\n",
    "    df_pdf = pd.read_pickle('data/pdflyers_df.pkl')\n",
    "    s0 = df.shape[0]\n",
    "    s1 = df.drop_duplicates('place_id').shape[0]\n",
    "    s2 = df[~df['place_id'].isin(df_pdf['place_id'])].shape[0]\n",
    "    dfu = df[~df['place_id'].isin(df_pdf['place_id'])].drop_duplicates('place_id')\n",
    "    s3 = dfu.shape[0]\n",
    "    print('Starting samples:',s0)\n",
    "    print(f'Duplicates: (Internal: {s0-s1}, External: {s0-s2})')\n",
    "    print('Remaining unique entries:',s3)\n",
    "    print('Yield: {:0.2%}, (Drop rate: {:0.2%})'.format((s3/s0),(s0-s3)/s0))\n",
    "    return dfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "snb_w25k = [gsearchNB(q,config.geo.CENTERW,radius=25000) for q in qlist.str.lower()]\n",
    "json.dump(snb_w25k,open('data/json/searchNB_W_allKW_r25k.json','w',encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "snb_w25k = json.load(open('data/json/searchNB_W_allKW_r25k.json','r',encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_searchNB(fpath):\n",
    "    with open(fpath,'r',encoding='utf-8') as fp:\n",
    "        snb = json.load(fp)\n",
    "    \n",
    "    df = pd.concat([json_normalize(res,['results'], sep='_').assign(\n",
    "            **{x:str(res[x]) for x in ['query','origin','radius']}) for res in snb],sort=False)\n",
    "    \n",
    "    df = drop_group_rename(df,pg_rev)\n",
    "    df['origin'] = df.origin.apply(destring_list)\n",
    "    \n",
    "    # drop 'open_now' and rearrange columns\n",
    "    df = df[['place_name', 'latlong', 'vicinity', 'keyword', 'place_group','types',\n",
    "       'rating', 'n_ratings', 'place_id','global_code', 'price_level', 'origin']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "snb_df = proc_searchNB('data/json/searchNB_W_allKW_r25k.json')\n",
    "snb_df = dedupe_placeid(snb_df)\n",
    "#snb_df['place_group'] = update_groups(snb_df,pg_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "dists_w25k = gdistances(snb_df.latlong, config.geo.CENTERW, 'data/json/distances_W_allKW_r25k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distances(df_base,dists_fpath):\n",
    "    \"\"\"Routing distance is calculated CENTERW -> location, geodesic distance is query origin -> location\"\"\"\n",
    "    df = df_base.copy()\n",
    "    with open(dists_fpath,'r',encoding='utf-8') as fp:\n",
    "        distslist = json.load(fp)\n",
    "    \n",
    "    df['geodesic_m'] = df.apply(lambda x: geodist.geodesic(x.latlong,x.origin).meters, axis=1)\n",
    "    \n",
    "    dists_df = pd.DataFrame([{'dest_addr':y,'travel_m':d['distance']['value'],'travel_secs':d['duration']['value']} \n",
    "             for x in distslist for y,d in zip(x['destination_addresses'],x['rows'][0]['elements'])],df.index)\n",
    "    \n",
    "    dists_df['dest_addr'] = dists_df['dest_addr'].str.replace(', ?USA|United States','')\n",
    "    df = pd.concat([df,dists_df],sort=False,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "snb_df = add_distances(snb_df,'data/json/distances_W_allKW_r25k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('data/pdflyers_df.pkl').append(snb_df, sort=False).to_pickle('data/pdflyers_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdf = pd.read_pickle('data/pdflyers_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def gpcode(coords):\n",
    "    \"\"\"Long runtime when API key is not provided\"\"\"\n",
    "    url_path='https://plus.codes/api?'\n",
    "    params = {'address':'{},{}'.format(*coords)}\n",
    "    resp = requests.get(url_path, params)\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globcodes = df_pdf.latlong.apply(gpcode)\n",
    "df_pdf['global_code'] = df_pdf.global_code.fillna(globcodes.apply(lambda x: x['plus_code']['global_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdf.to_pickle('data/pdflyers_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placed Flyers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with raw export from the Map Markers app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def proc_visited_locs(flyer_fpath, posdf_path='data/open_pos_df.pkl'):\n",
    "    \"\"\"geocoder: ('here','gmaps','bing', or None)\"\"\"\n",
    "    df = pd.read_csv(flyer_fpath)\n",
    "\n",
    "    # ex. Marker 1-gas station-Holiday -> keyword:gas station, place_name:Holiday\n",
    "    df[['keyword','place_name']] = df.apply(lambda x: x.Title.split('-'), result_type='expand',axis=1).iloc[:,1:]\n",
    "\n",
    "    # append quantity where missing\n",
    "    df['Description'] = df['Description'].apply(lambda x: x+'-1' if x=='Yes' else (x+'-0' if x=='No' else x))\n",
    "    df['n_flyers'] = df['Description'].str.split('-').str[1].astype(np.int)\n",
    "    \n",
    "    df['latlong'] = df.apply(lambda x: np.round([x.Latitude,x.Longitude],6),axis=1)\n",
    "    \n",
    "    # Correct datetime for previously placed flyers\n",
    "    fill_dts = pd.Series(['10/16/2019 11:46','10/16/2019 14:23','10/19/2019 18:12'])\n",
    "    df['Timestamp'] = df['Timestamp'].mask(lambda x: x.str.split().str[0] == '11/10/2019',fill_dts).pipe(pd.to_datetime)\n",
    "\n",
    "    # reorder and select desired columns\n",
    "    df = df[['Timestamp','place_name','keyword','n_flyers', 'latlong']]\n",
    "    \n",
    "    df['geodesic_m'] = df['latlong'].apply(lambda x: geodist.geodesic(config.geo.CENTERW,x).meters)\n",
    "    \n",
    "    # filter open positions down to 100k meters from shop\n",
    "    df_nbopos = pd.read_pickle(posdf_path).query('geodesic_m < 100000')\n",
    "    \n",
    "    mindex = df['latlong'].apply(lambda x: np.argmin([geodist.geodesic(x, v).meters for v in df_nbopos['latlong']]))\n",
    "    df[['nearest_position','nearest_position_mi']] = pd.DataFrame(\n",
    "        [(f\"{s.Location_Host}: {s.Position}\",geodist.geodesic(l,s['latlong']).miles) \n",
    "         for l,(_,s) in zip(df['latlong'],df_nbopos.iloc[mindex].iterrows())])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder name</th>\n",
       "      <th>Folder color</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Color</th>\n",
       "      <th>Phone number</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Day_00</td>\n",
       "      <td>ff2196f3</td>\n",
       "      <td>45.130812</td>\n",
       "      <td>-93.355416</td>\n",
       "      <td>Flyer 0.0-gas station-Kwik Trip</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ff2196f3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/10/2019 12:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Day_00</td>\n",
       "      <td>ff2196f3</td>\n",
       "      <td>45.317972</td>\n",
       "      <td>-93.935816</td>\n",
       "      <td>Flyer 0.1-park-Lake Maria State Park</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ff2196f3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/10/2019 12:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Day_00</td>\n",
       "      <td>ff2196f3</td>\n",
       "      <td>45.136333</td>\n",
       "      <td>-93.169280</td>\n",
       "      <td>Flyer 0.2-laundry-Maytag Laundry</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ff2196f3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/10/2019 12:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ff71b300</td>\n",
       "      <td>44.985114</td>\n",
       "      <td>-93.183377</td>\n",
       "      <td>Flyer 12-college-McNeal Hall</td>\n",
       "      <td>Yes-2</td>\n",
       "      <td>ff71b300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/16/2019 16:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ff71b300</td>\n",
       "      <td>45.059031</td>\n",
       "      <td>-93.198671</td>\n",
       "      <td>Marker 13-gas station-Minnoco</td>\n",
       "      <td>No</td>\n",
       "      <td>fff44336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/16/2019 16:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Folder name Folder color   Latitude  Longitude  \\\n",
       "0      Day_00     ff2196f3  45.130812 -93.355416   \n",
       "1      Day_00     ff2196f3  45.317972 -93.935816   \n",
       "2      Day_00     ff2196f3  45.136333 -93.169280   \n",
       "3         NaN     ff71b300  44.985114 -93.183377   \n",
       "4         NaN     ff71b300  45.059031 -93.198671   \n",
       "\n",
       "                                  Title Description     Color  Phone number  \\\n",
       "0       Flyer 0.0-gas station-Kwik Trip         Yes  ff2196f3           NaN   \n",
       "1  Flyer 0.1-park-Lake Maria State Park         Yes  ff2196f3           NaN   \n",
       "2      Flyer 0.2-laundry-Maytag Laundry         Yes  ff2196f3           NaN   \n",
       "3          Flyer 12-college-McNeal Hall       Yes-2  ff71b300           NaN   \n",
       "4         Marker 13-gas station-Minnoco          No  fff44336           NaN   \n",
       "\n",
       "          Timestamp  \n",
       "0  11/10/2019 12:46  \n",
       "1  11/10/2019 12:48  \n",
       "2  11/10/2019 12:50  \n",
       "3  11/16/2019 16:06  \n",
       "4  11/16/2019 16:58  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/csv/placed_day2.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_visit_day2= proc_visited_locs('data/csv/placed_day2.csv','data/open_pos_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>place_name</th>\n",
       "      <th>keyword</th>\n",
       "      <th>n_flyers</th>\n",
       "      <th>latlong</th>\n",
       "      <th>geodesic_m</th>\n",
       "      <th>nearest_position</th>\n",
       "      <th>nearest_position_mi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-16 11:46:00</td>\n",
       "      <td>Kwik Trip</td>\n",
       "      <td>gas station</td>\n",
       "      <td>1</td>\n",
       "      <td>[45.130812, -93.355416]</td>\n",
       "      <td>29075.875029</td>\n",
       "      <td>Anoka County Crew: Andover Field Crew Member</td>\n",
       "      <td>6.673407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-16 14:23:00</td>\n",
       "      <td>Lake Maria State Park</td>\n",
       "      <td>park</td>\n",
       "      <td>1</td>\n",
       "      <td>[45.317972, -93.935816]</td>\n",
       "      <td>78569.048931</td>\n",
       "      <td>Three Rivers Crews: Central Minnesota Field Cr...</td>\n",
       "      <td>18.088296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-19 18:12:00</td>\n",
       "      <td>Maytag Laundry</td>\n",
       "      <td>laundry</td>\n",
       "      <td>1</td>\n",
       "      <td>[45.136333, -93.16928]</td>\n",
       "      <td>20657.421746</td>\n",
       "      <td>Anoka County Crew: Andover Field Crew Member</td>\n",
       "      <td>8.552833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-11-16 16:06:00</td>\n",
       "      <td>McNeal Hall</td>\n",
       "      <td>college</td>\n",
       "      <td>2</td>\n",
       "      <td>[44.985114, -93.183377]</td>\n",
       "      <td>9160.545053</td>\n",
       "      <td>Youth Outdoors Crews #1-2: Youth Outdoors Crew...</td>\n",
       "      <td>1.479060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-11-16 16:58:00</td>\n",
       "      <td>Minnoco</td>\n",
       "      <td>gas station</td>\n",
       "      <td>0</td>\n",
       "      <td>[45.059031, -93.198671]</td>\n",
       "      <td>14584.239211</td>\n",
       "      <td>Youth Outdoors Crews #1-2: Youth Outdoors Crew...</td>\n",
       "      <td>6.147447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp             place_name      keyword  n_flyers  \\\n",
       "0 2019-10-16 11:46:00              Kwik Trip  gas station         1   \n",
       "1 2019-10-16 14:23:00  Lake Maria State Park         park         1   \n",
       "2 2019-10-19 18:12:00         Maytag Laundry      laundry         1   \n",
       "3 2019-11-16 16:06:00            McNeal Hall      college         2   \n",
       "4 2019-11-16 16:58:00                Minnoco  gas station         0   \n",
       "\n",
       "                   latlong    geodesic_m  \\\n",
       "0  [45.130812, -93.355416]  29075.875029   \n",
       "1  [45.317972, -93.935816]  78569.048931   \n",
       "2   [45.136333, -93.16928]  20657.421746   \n",
       "3  [44.985114, -93.183377]   9160.545053   \n",
       "4  [45.059031, -93.198671]  14584.239211   \n",
       "\n",
       "                                    nearest_position  nearest_position_mi  \n",
       "0       Anoka County Crew: Andover Field Crew Member             6.673407  \n",
       "1  Three Rivers Crews: Central Minnesota Field Cr...            18.088296  \n",
       "2       Anoka County Crew: Andover Field Crew Member             8.552833  \n",
       "3  Youth Outdoors Crews #1-2: Youth Outdoors Crew...             1.479060  \n",
       "4  Youth Outdoors Crews #1-2: Youth Outdoors Crew...             6.147447  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visit_day2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "details_day2= gpdetails_df(df_visit_day2,'place_name','latlong',fpath='data/json/details_visited_day2.json',id_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_details(details_fpath, df_visited):\n",
    "    with open(details_fpath, 'r', encoding='utf-8') as fp:\n",
    "        df = json_normalize(json.load(fp), sep='_')\n",
    "    \n",
    "    df = drop_group_rename(df,pg_rev)\n",
    "    df['dest_addr'] = df['dest_addr'].str.replace(', ?USA|United States','')\n",
    "    df = df.combine_first(df_visited)\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df['n_flyers'] = df['n_flyers'].astype(np.int)\n",
    "    # reorder columns\n",
    "    df = df[['Timestamp','place_name','keyword','place_group','types','n_flyers','dest_addr','vicinity',\n",
    "             'latlong', 'global_code','geodesic_m', 'nearest_position','nearest_position_mi', 'place_id']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>place_name</th>\n",
       "      <th>keyword</th>\n",
       "      <th>place_group</th>\n",
       "      <th>types</th>\n",
       "      <th>n_flyers</th>\n",
       "      <th>dest_addr</th>\n",
       "      <th>vicinity</th>\n",
       "      <th>latlong</th>\n",
       "      <th>global_code</th>\n",
       "      <th>geodesic_m</th>\n",
       "      <th>nearest_position</th>\n",
       "      <th>nearest_position_mi</th>\n",
       "      <th>place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-16 11:46:00</td>\n",
       "      <td>Kwik Trip #880</td>\n",
       "      <td>gas station</td>\n",
       "      <td>automotive</td>\n",
       "      <td>[convenience_store, atm, gas_station, finance,...</td>\n",
       "      <td>1</td>\n",
       "      <td>5801 96th Ave N, Brooklyn Park, MN 55443</td>\n",
       "      <td>5801 96th Avenue North, Brooklyn Park</td>\n",
       "      <td>[45.130751, -93.355403]</td>\n",
       "      <td>86Q84JJV+8R</td>\n",
       "      <td>29075.875029</td>\n",
       "      <td>Anoka County Crew: Andover Field Crew Member</td>\n",
       "      <td>6.673407</td>\n",
       "      <td>ChIJS4-HKik6s1IRU3_pSNE87kY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-16 14:23:00</td>\n",
       "      <td>Lake Maria State Park</td>\n",
       "      <td>park</td>\n",
       "      <td>park_camp</td>\n",
       "      <td>[campground, tourist_attraction, lodging, park...</td>\n",
       "      <td>1</td>\n",
       "      <td>11411 Clementa Ave NW, Monticello, MN 55362</td>\n",
       "      <td>11411 Clementa Avenue Northwest, Monticello</td>\n",
       "      <td>[45.315063, -93.951519]</td>\n",
       "      <td>86Q8828X+29</td>\n",
       "      <td>78569.048931</td>\n",
       "      <td>Three Rivers Crews: Central Minnesota Field Cr...</td>\n",
       "      <td>18.088296</td>\n",
       "      <td>ChIJVZOc2gWatFIRpusOTu6RuGs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-19 18:12:00</td>\n",
       "      <td>Maytag Laundry</td>\n",
       "      <td>laundry</td>\n",
       "      <td>services</td>\n",
       "      <td>[laundry, point_of_interest, establishment]</td>\n",
       "      <td>1</td>\n",
       "      <td>9010 Griggs Ave, Circle Pines, MN 55014</td>\n",
       "      <td>9010 Griggs Avenue, Circle Pines</td>\n",
       "      <td>[45.1363, -93.169299]</td>\n",
       "      <td>86Q84RPJ+G7</td>\n",
       "      <td>20657.421746</td>\n",
       "      <td>Anoka County Crew: Andover Field Crew Member</td>\n",
       "      <td>8.552833</td>\n",
       "      <td>ChIJy_rCW1oms1IRFFbSVWpCngA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-11-16 16:06:00</td>\n",
       "      <td>McNeal Hall</td>\n",
       "      <td>college</td>\n",
       "      <td>academic</td>\n",
       "      <td>[university, point_of_interest, establishment]</td>\n",
       "      <td>2</td>\n",
       "      <td>1985 Buford Ave, St Paul, MN 55108</td>\n",
       "      <td>1985 Buford Avenue, Saint Paul</td>\n",
       "      <td>[44.984688, -93.183543]</td>\n",
       "      <td>86P8XRM8+VH</td>\n",
       "      <td>9160.545053</td>\n",
       "      <td>Youth Outdoors Crews #1-2: Youth Outdoors Crew...</td>\n",
       "      <td>1.479060</td>\n",
       "      <td>ChIJqQeq7IIss1IRgIzIpO0CI4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-11-16 16:58:00</td>\n",
       "      <td>Minnoco XPRESS</td>\n",
       "      <td>gas station</td>\n",
       "      <td>automotive</td>\n",
       "      <td>[gas_station, point_of_interest, establishment]</td>\n",
       "      <td>0</td>\n",
       "      <td>574 Old Hwy 8 NW, New Brighton, MN 55112</td>\n",
       "      <td>574 Old Highway 8 Northwest, New Brighton</td>\n",
       "      <td>[45.058945, -93.198574]</td>\n",
       "      <td>86Q83R52+HH</td>\n",
       "      <td>14584.239211</td>\n",
       "      <td>Youth Outdoors Crews #1-2: Youth Outdoors Crew...</td>\n",
       "      <td>6.147447</td>\n",
       "      <td>ChIJq6YIFNAus1IRNafiQLBN1oY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp             place_name      keyword place_group  \\\n",
       "0 2019-10-16 11:46:00         Kwik Trip #880  gas station  automotive   \n",
       "1 2019-10-16 14:23:00  Lake Maria State Park         park   park_camp   \n",
       "2 2019-10-19 18:12:00         Maytag Laundry      laundry    services   \n",
       "3 2019-11-16 16:06:00            McNeal Hall      college    academic   \n",
       "4 2019-11-16 16:58:00         Minnoco XPRESS  gas station  automotive   \n",
       "\n",
       "                                               types  n_flyers  \\\n",
       "0  [convenience_store, atm, gas_station, finance,...         1   \n",
       "1  [campground, tourist_attraction, lodging, park...         1   \n",
       "2        [laundry, point_of_interest, establishment]         1   \n",
       "3     [university, point_of_interest, establishment]         2   \n",
       "4    [gas_station, point_of_interest, establishment]         0   \n",
       "\n",
       "                                     dest_addr  \\\n",
       "0     5801 96th Ave N, Brooklyn Park, MN 55443   \n",
       "1  11411 Clementa Ave NW, Monticello, MN 55362   \n",
       "2      9010 Griggs Ave, Circle Pines, MN 55014   \n",
       "3           1985 Buford Ave, St Paul, MN 55108   \n",
       "4     574 Old Hwy 8 NW, New Brighton, MN 55112   \n",
       "\n",
       "                                      vicinity                  latlong  \\\n",
       "0        5801 96th Avenue North, Brooklyn Park  [45.130751, -93.355403]   \n",
       "1  11411 Clementa Avenue Northwest, Monticello  [45.315063, -93.951519]   \n",
       "2             9010 Griggs Avenue, Circle Pines    [45.1363, -93.169299]   \n",
       "3               1985 Buford Avenue, Saint Paul  [44.984688, -93.183543]   \n",
       "4    574 Old Highway 8 Northwest, New Brighton  [45.058945, -93.198574]   \n",
       "\n",
       "   global_code    geodesic_m  \\\n",
       "0  86Q84JJV+8R  29075.875029   \n",
       "1  86Q8828X+29  78569.048931   \n",
       "2  86Q84RPJ+G7  20657.421746   \n",
       "3  86P8XRM8+VH   9160.545053   \n",
       "4  86Q83R52+HH  14584.239211   \n",
       "\n",
       "                                    nearest_position  nearest_position_mi  \\\n",
       "0       Anoka County Crew: Andover Field Crew Member             6.673407   \n",
       "1  Three Rivers Crews: Central Minnesota Field Cr...            18.088296   \n",
       "2       Anoka County Crew: Andover Field Crew Member             8.552833   \n",
       "3  Youth Outdoors Crews #1-2: Youth Outdoors Crew...             1.479060   \n",
       "4  Youth Outdoors Crews #1-2: Youth Outdoors Crew...             6.147447   \n",
       "\n",
       "                      place_id  \n",
       "0  ChIJS4-HKik6s1IRU3_pSNE87kY  \n",
       "1  ChIJVZOc2gWatFIRpusOTu6RuGs  \n",
       "2  ChIJy_rCW1oms1IRFFbSVWpCngA  \n",
       "3  ChIJqQeq7IIss1IRgIzIpO0CI4o  \n",
       "4  ChIJq6YIFNAus1IRNafiQLBN1oY  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visit_details = add_details('data/json/details_visited_day2.json',df_visit_day2)\n",
    "df_visit_details.to_pickle('data/visited_details_all_df.pkl')\n",
    "df_visit_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visit_details = pd.read_pickle('data/visited_details_all_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "nbvisited = gsearchNB_df(df_visit_details,'keyword','latlong',fpath='data/json/searchNB_visited_day2_r25k.json',radius=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nbvisit = proc_searchNB('data/json/searchNB_visited_day2_r25k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdf = pd.read_pickle('data/pdflyers_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((520, 12), (133, 12), (12, 12))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nbvisit.shape, df_nbvisit.drop_duplicates('place_id').shape,df_nbvisit[~df_nbvisit.place_id.isin(df_pdf.place_id)].drop_duplicates('place_id').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the growing list of places and the limited set of keywords used, we are experiencing greatly diminished returns from further queries. From an initial 520 places, our non-duplicate yield is only 12, what's more, nearly 400 were duplicates within the query itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nbvisit = df_nbvisit[~df_nbvisit.place_id.isin(df_pdf.place_id)].drop_duplicates('place_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "dists_day2 = gdistances(df_nbvisit.latlong, config.geo.CENTERW,'data/json/distances_W_NBday2_r25k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nbvisit = add_distances(df_nbvisit,'data/json/distances_W_NBday2_r25k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('data/pdflyers_df.pkl').append(df_nbvisit,sort=False).to_pickle('data/pdflyers_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_US(address):\n",
    "    rgx = re.compile(r', ?(USA|United States)')\n",
    "    return rgx.sub('',address)\n",
    "\n",
    "def geocode_df(df_geo, coords_col='latlong', addr_col='dest_addr', geocoder='here', reverse=True):\n",
    "    df = df_geo.copy()\n",
    "    #usecol,assigncol = (coords_col,addr_col) if reverse else (addr_col,coords_col)\n",
    "    if geocoder == 'here': \n",
    "        geoc = geopy.Here(config.HERE_APPID,config.HERE_APPCODE)\n",
    "        gc_func = geoc.reverse if reverse else geoc.geocode\n",
    "        addr_proc_fn = lambda x: strip_US(gc_func(x).raw['Location']['Address']['Label']) # here\n",
    "    elif geocoder == 'gmaps': \n",
    "        geoc = geopy.GoogleV3(config.GMAPS_KEY)\n",
    "        gc_func = geoc.reverse if reverse else geoc.geocode\n",
    "        addr_proc_fn = lambda x: strip_US(ggeocode(geoc,x).address) # gmaps\n",
    "    elif geocoder == 'bing': \n",
    "        geoc = geopy.Bing(config.BING_KEY)\n",
    "        gc_func = geoc.reverse if reverse else geoc.geocode\n",
    "        addr_proc_fn = lambda x: strip_US(gc_func(x).address) # bing\n",
    "    else: \n",
    "        raise NotImplementedError('Valid options are (here|gmaps|bing)')\n",
    "    \n",
    "    if not reverse:\n",
    "        df[coords_col] = df[addr_col].apply(lambda x: np.round(gc_func(x).point[:2],6))\n",
    "        return df\n",
    "    \n",
    "    df[addr_col] = df[coords_col].apply(addr_proc_fn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_openpos(opos_fpath, geocoder='here'):\n",
    "    # Get open posisions on CCM websie\n",
    "    co_geo = json.load(open(opos_fpath,'r', encoding='utf-8'))\n",
    "    opgeo_df = pd.DataFrame([x['properties'] for x in co_geo['features']])\n",
    "    df = geocode_df(opgeo_df,addr_col='Address', geocoder=geocoder, reverse=False)\n",
    "    df['geodesic_m'] = df['latlong'].apply(lambda x: geodist.geodesic(config.geo.CENTERW,x).meters)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "oppos_df = proc_openpos('data/geospatial/Currently_Open.csv.geojson',geocoder='gmaps')\n",
    "oppos_df.to_pickle('data/open_pos_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "oppos_df = pd.read_pickle('data/open_pos_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearby open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_queries(df_openpos, keep_types=None):\n",
    "    if keep_types is None:\n",
    "        # 'government_office' is not a real type, 'local_government_office' resulted in worse search results\n",
    "        keep_types = ['book_store','city_hall','convenience_store','gas_station', \n",
    "                      'laundry', 'library','university', 'government_office']\n",
    "    \n",
    "    kt_queries = [x.replace('_', ' ') for x in keep_types]\n",
    "    nearpos_unq = df_openpos.drop_duplicates('Address').query('geodesic_m < 100000 & geodesic_m > 55')['latlong']\n",
    "    qmap = [(pos, ktq) for pos in nearpos_unq for ktq in kt_queries]\n",
    "    return qmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "qmap = build_queries(oppos_df)\n",
    "nbopenpos = try_jsave([gsearchNB(q, co, radius=15000) for co,q in qmap],'data/json/searchNB_opos_typeKW_r15k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nbo = proc_searchNB('data/json/searchNB_opos_typeKW_r15k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting samples: 1775\n",
      "Duplicates: (Internal: 965, External: 1354)\n",
      "Remaining unique entries: 327\n",
      "Yield: 18.42%, (Drop rate: 81.58%)\n"
     ]
    }
   ],
   "source": [
    "df_nbo = dedupe_placeid(df_nbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "nbo_dists = gdistances(df_nbo.latlong, config.geo.CENTERW, 'data/json/distances_opos_r15k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nbo = add_distances(df_nbo,'data/json/distances_opos_r15k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('data/pdflyers_df.pkl').append(df_nbo,sort=False).to_pickle('data/pdflyers_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearpos_df = pd.read_pickle('data/nearpos_df.pkl')\n",
    "pdflyers_df = pd.read_pickle('data/pdflyers_df.pkl')\n",
    "visited_df = pd.read_pickle('data/flyers_df.pkl')\n",
    "openpos_df = pd.read_pickle('data/open_pos_df.pkl')\n",
    "placed_df = pd.read_pickle('data/flyers_all_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Name Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_list = [y for x in pdflyers_df.types for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "flys_df = pdflyers_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_df = pd.concat([flys_df[['place_name','keyword','place_group']],\n",
    "           pd.DataFrame(flys_df.types.tolist(), \n",
    "                        columns=[f'type_{i}' for i in range(flys_df.types.apply(len).max())])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rygu\\Anaconda3\\envs\\scrape\\lib\\site-packages\\pandas\\core\\strings.py:1843: UserWarning:\n",
      "\n",
      "This pattern has match groups. To actually get the groups, use str.extract.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_name</th>\n",
       "      <th>latlong</th>\n",
       "      <th>vicinity</th>\n",
       "      <th>dest_addr</th>\n",
       "      <th>keyword</th>\n",
       "      <th>types</th>\n",
       "      <th>rating</th>\n",
       "      <th>n_ratings</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place_group</th>\n",
       "      <th>geodesic_meters</th>\n",
       "      <th>travel_meters</th>\n",
       "      <th>travel_secs</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>Griggs Recreation Center</td>\n",
       "      <td>[44.965402, -93.150134]</td>\n",
       "      <td>1188 Hubbard Ave, St Paul</td>\n",
       "      <td>1188 Hubbard Ave, St Paul, MN 55104</td>\n",
       "      <td>Recreational Facility</td>\n",
       "      <td>[point_of_interest, establishment]</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26</td>\n",
       "      <td>ChIJ469k-08rs1IR99hEZOzo2SY</td>\n",
       "      <td>other</td>\n",
       "      <td>19910.362355</td>\n",
       "      <td>24534</td>\n",
       "      <td>1572</td>\n",
       "      <td>[45.143366, -93.120994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>St Paul Recreation Center</td>\n",
       "      <td>[44.97146, -93.048825]</td>\n",
       "      <td>1020 Duluth St, St Paul</td>\n",
       "      <td>1020 Duluth St, St Paul, MN 55106</td>\n",
       "      <td>Recreational Facility</td>\n",
       "      <td>[point_of_interest, establishment]</td>\n",
       "      <td>4.2</td>\n",
       "      <td>11</td>\n",
       "      <td>ChIJiUw508TUslIRjc6dj4W9r1E</td>\n",
       "      <td>other</td>\n",
       "      <td>19932.219256</td>\n",
       "      <td>30322</td>\n",
       "      <td>1562</td>\n",
       "      <td>[45.143366, -93.120994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Wilder Recreation Center</td>\n",
       "      <td>[44.969889, -93.076921]</td>\n",
       "      <td>958 Jessie St, St Paul</td>\n",
       "      <td>958 Jessie St, St Paul, MN 55130</td>\n",
       "      <td>Recreational Facility</td>\n",
       "      <td>[point_of_interest, establishment]</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20</td>\n",
       "      <td>ChIJgQGmSTjVslIREh7SevWVKgk</td>\n",
       "      <td>other</td>\n",
       "      <td>19589.108651</td>\n",
       "      <td>28437</td>\n",
       "      <td>1318</td>\n",
       "      <td>[45.143366, -93.120994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>Saint Paul Recreation Center</td>\n",
       "      <td>[44.952654, -93.184722]</td>\n",
       "      <td>2000 St Anthony Ave, St Paul</td>\n",
       "      <td>2000 St Anthony Ave, St Paul, MN 55104</td>\n",
       "      <td>Recreational Facility</td>\n",
       "      <td>[point_of_interest, establishment]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ChIJ5RHMFPwp9ocRtZIppZBB2Dk</td>\n",
       "      <td>other</td>\n",
       "      <td>21780.841782</td>\n",
       "      <td>28586</td>\n",
       "      <td>1662</td>\n",
       "      <td>[45.143366, -93.120994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>Rice Recreation Center</td>\n",
       "      <td>[44.972775, -93.110451]</td>\n",
       "      <td>1021 Marion St, St Paul</td>\n",
       "      <td>1021 Marion St, St Paul, MN 55117</td>\n",
       "      <td>Recreational Facility</td>\n",
       "      <td>[local_government_office, point_of_interest, e...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>ChIJp4wvr7wqs1IRHC8xfM_Bxho</td>\n",
       "      <td>government</td>\n",
       "      <td>18976.433244</td>\n",
       "      <td>28691</td>\n",
       "      <td>1351</td>\n",
       "      <td>[45.143366, -93.120994]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      place_name                  latlong  \\\n",
       "64      Griggs Recreation Center  [44.965402, -93.150134]   \n",
       "65     St Paul Recreation Center   [44.97146, -93.048825]   \n",
       "66      Wilder Recreation Center  [44.969889, -93.076921]   \n",
       "67  Saint Paul Recreation Center  [44.952654, -93.184722]   \n",
       "68        Rice Recreation Center  [44.972775, -93.110451]   \n",
       "\n",
       "                        vicinity                               dest_addr  \\\n",
       "64     1188 Hubbard Ave, St Paul     1188 Hubbard Ave, St Paul, MN 55104   \n",
       "65       1020 Duluth St, St Paul       1020 Duluth St, St Paul, MN 55106   \n",
       "66        958 Jessie St, St Paul        958 Jessie St, St Paul, MN 55130   \n",
       "67  2000 St Anthony Ave, St Paul  2000 St Anthony Ave, St Paul, MN 55104   \n",
       "68       1021 Marion St, St Paul       1021 Marion St, St Paul, MN 55117   \n",
       "\n",
       "                  keyword                                              types  \\\n",
       "64  Recreational Facility                 [point_of_interest, establishment]   \n",
       "65  Recreational Facility                 [point_of_interest, establishment]   \n",
       "66  Recreational Facility                 [point_of_interest, establishment]   \n",
       "67  Recreational Facility                 [point_of_interest, establishment]   \n",
       "68  Recreational Facility  [local_government_office, point_of_interest, e...   \n",
       "\n",
       "    rating  n_ratings                     place_id place_group  \\\n",
       "64     4.5         26  ChIJ469k-08rs1IR99hEZOzo2SY       other   \n",
       "65     4.2         11  ChIJiUw508TUslIRjc6dj4W9r1E       other   \n",
       "66     4.1         20  ChIJgQGmSTjVslIREh7SevWVKgk       other   \n",
       "67     2.0          1  ChIJ5RHMFPwp9ocRtZIppZBB2Dk       other   \n",
       "68     4.0          6  ChIJp4wvr7wqs1IRHC8xfM_Bxho  government   \n",
       "\n",
       "    geodesic_meters  travel_meters  travel_secs                   origin  \n",
       "64     19910.362355          24534         1572  [45.143366, -93.120994]  \n",
       "65     19932.219256          30322         1562  [45.143366, -93.120994]  \n",
       "66     19589.108651          28437         1318  [45.143366, -93.120994]  \n",
       "67     21780.841782          28586         1662  [45.143366, -93.120994]  \n",
       "68     18976.433244          28691         1351  [45.143366, -93.120994]  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flys_df[flys_df.place_name.str.contains('[^\\w]Rec(reation)? center', case=False)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gym, health                                42\n",
       "cafe, restaurant                           37\n",
       "pharmacy, health                           31\n",
       "bar, restaurant                            28\n",
       "doctor, health                             27\n",
       "atm, finance                               26\n",
       "electronics_store, home_goods_store        25\n",
       "hair_care, health                          23\n",
       "beauty_salon, hair_care                    22\n",
       "bakery, meal_takeaway                      21\n",
       "post_office, finance                       20\n",
       "church, place_of_worship                   20\n",
       "meal_delivery, restaurant                  19\n",
       "meal_takeaway, cafe, restaurant            17\n",
       "meal_takeaway, cafe                        17\n",
       "bakery, meal_takeaway, cafe, restaurant    16\n",
       "bakery, meal_takeaway, cafe                16\n",
       "cafe, bakery                               16\n",
       "grocery_or_supermarket, supermarket        15\n",
       "cafe, bakery, restaurant                   13\n",
       "dentist, health                            13\n",
       "bakery, restaurant                         13\n",
       "bank, finance                              13\n",
       "city_hall, local_government_office         12\n",
       "supermarket, grocery_or_supermarket        11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 11),stop_words=['establishment','point_of_interest','food','store'],min_df=2)\n",
    "typec = cv.fit_transform(flys_df.types.str.join(' '))\n",
    "pd.Series(typec.sum(axis=0).A1,[', '.join(x.split()) for x in cv.get_feature_names()]).sort_values(ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('cafe', 'food', 'store'), 96),\n",
       " (('food', 'restaurant', 'store'), 83),\n",
       " (('food', 'grocery_or_supermarket', 'store'), 57),\n",
       " (('cafe', 'food', 'restaurant'), 53),\n",
       " (('cafe', 'restaurant', 'store'), 53),\n",
       " (('bakery', 'food', 'store'), 47),\n",
       " (('bakery', 'food', 'restaurant'), 40),\n",
       " (('bakery', 'restaurant', 'store'), 40),\n",
       " (('bakery', 'cafe', 'food'), 38),\n",
       " (('bakery', 'cafe', 'restaurant'), 38),\n",
       " (('bakery', 'cafe', 'store'), 38),\n",
       " (('health', 'pharmacy', 'store'), 36),\n",
       " (('convenience_store', 'food', 'store'), 35),\n",
       " (('bar', 'food', 'restaurant'), 33),\n",
       " (('food', 'grocery_or_supermarket', 'supermarket'), 29)]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtypes = flys_df.types.apply(lambda x: [y for y in x if y not in ['establishment','point_of_interest']])\n",
    "Counter([*itertools.chain(*map(lambda x: itertools.combinations(sorted(x),3),filtypes))]).most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgvec = spacy.load('en_vectors_web_lg')\n",
    "kwlist = pd.Series(placedist_df.keyword.unique())\n",
    "kwnlp = kwlist.apply(lgvec)\n",
    "keywords_nlp = [lgvec(word) for word in placedist_df.keyword.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grocery Store 1.0\n",
      "Library 0.4034122878941292\n",
      "Gym 0.3965229374953233\n",
      "Recreational Facility 0.3357720535102543\n",
      "Church 0.303269721075901\n",
      "Laundromat 0.4230004799201568\n",
      "Coffee Shop 0.7037528864224344\n",
      "Community Center 0.364748026759436\n",
      "Union Hall 0.3333642744282254\n",
      "Beauty Salon 0.39430854068295423\n",
      "Bookstore 0.5803768972279834\n",
      "Restaurant 0.5056170944476143\n",
      "Bar 0.3874670304787477\n",
      "Convenience Store 0.8632801182253251\n",
      "Music Store 0.7018800601240646\n",
      "Apartment complex 0.3623733390384342\n",
      "Pharmacy 0.4818274937486199\n",
      "Qdoba 0.03744478445549931\n",
      "Panera Bread 0.37760299377586787\n",
      "Caribou Coffee 0.393244702926105\n",
      "Barnes & Noble 0.26353069124756967\n",
      "Whole Foods 0.5179779057685318\n",
      "Pot Belly Sandwich Shop 0.5705874247342473\n",
      "Starbucks 0.43917914241117906\n",
      "Jimmy John's 0.25454560863923054\n",
      "Hy-Vee 0.060538348127758726\n",
      "Post Office 0.4014902817160768\n",
      "Town Hall 0.4078356873927435\n",
      "Barber Shop 0.6494405166328542\n",
      "Beauty Parlor 0.37723857795717064\n",
      "Nail Salon 0.39181234556402345\n",
      "Ice Cream Stand 0.4188294740789496\n",
      "Supermarket 0.7820693840661119\n",
      "College 0.26723087540822177\n",
      "Mall 0.6714354914922972\n",
      "Doctor 0.2917514750926999\n",
      "Dentist 0.2676773575488203\n",
      "Gas Station 0.4000106399593747\n",
      "Auto Repair Shop 0.5307852867339208\n",
      "Day Care Center 0.4338122026502734\n",
      "Chamber of Commerce 0.29953815956642355\n",
      "Bank 0.37325080389583415\n",
      "Credit Union 0.32907104443111623\n",
      "Hardware Store 0.7229545089120136\n",
      "Fitness Center 0.3786675554015116\n"
     ]
    }
   ],
   "source": [
    "for kw in keywords_nlp:\n",
    "    print(kw,keywords_nlp[0].similarity(kw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.091465205"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.wv.similarity(kwlist[0],kwlist[25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearpos_df = pd.read_pickle('data/nearpos_df.pkl')\n",
    "pdflyers_df = pd.read_pickle('data/pdflyers_df.pkl')\n",
    "visited_df = pd.read_pickle('data/flyers_df.pkl')\n",
    "openpos_df = pd.read_pickle('data/open_pos_df.pkl')\n",
    "visited_all = pd.read_pickle('data/flyers_all_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cleanplaces_df(df, drop_cols=None):\n",
    "    if drop_cols is None:\n",
    "        drop_cols = ['vicinity','rating','n_ratings','place_id','geodesic_meters']\n",
    "    folium_df = df.drop(columns=drop_cols).copy()\n",
    "    folium_df['miles'] = (folium_df.travel_meters/METERMILE).round(2)\n",
    "    folium_df['mins'] = (folium_df.travel_secs/60).round(1)\n",
    "    folium_df = folium_df.drop(columns=['travel_meters','travel_secs'])\n",
    "    return folium_df\n",
    "\n",
    "def cleanvisted_df(df, keep_cols=None):\n",
    "    if keep_cols is None:\n",
    "        keep_cols = ['place_name','dest_addr','n_flyers','keyword','types','pinloc','Timestamp']\n",
    "    return df[keep_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandf_pdist = cleanplaces_df(pdflyers_df)\n",
    "cleandf_visit = cleanvisted_df(visited_df)\n",
    "near_pos_df = openpos_df[openpos_df.geodesic_meters.lt(42000)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
